{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df5c2ff",
   "metadata": {},
   "source": [
    "# ðŸŽµ Music Genre Classification: A Machine Learning Journey\n",
    "\n",
    "Welcome to this detailed exploration of music genre classification using the GTZAN dataset! In this project, we aim to classify music clips into genres such as jazz, classical, rock, and more, based on audio features extracted from 30-second audio samples. This notebook serves as both a technical implementation and a narrative blog post, guiding you through the process of data exploration, visualization, preprocessing, model training, and evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a213303",
   "metadata": {},
   "source": [
    "## Motivation - Why Music Genre Classification?\n",
    "\n",
    "ðŸŽ¯I'm deeply interested in music and often find myself wanting to organize my collection by genre. However, manually checking and classifying each song is time-consuming and tedious. This project was born out of a desire to automate that processâ€”enabling genre classification in a way that saves time and effort. While there is an upfront cost in terms of model training, once trained, the system can quickly classify new tracks with minimal delay. This is just an initial attempt to solve a personal pain pointâ€”not a final solution, but a promising step toward making music organization more efficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14455a31",
   "metadata": {},
   "source": [
    "## Connection to Multimodal Learning: A Historical Perspective\n",
    "\n",
    "Multimodal learning involves integrating multiple data types (e.g., audio, text, images) to improve model performance and understanding. Music genre classification, as implemented in the GTZAN project, is primarily unimodal, focusing on audio features. However, it connects to multimodal learning through its potential to incorporate additional modalities, such as lyrics or visual album covers, to enhance classification accuracy and robustness.\n",
    "\n",
    "### Historical Context\n",
    "\n",
    "- **Early MIR (2000s)**: The GTZAN dataset, introduced by Tzanetakis and Cook in 2002, marked a milestone in MIR (Music Information Retrieval) by providing a standardized dataset for genre classification. Early work relied on handcrafted audio features like MFCCs and statistical models (e.g., SVMs, GMMs).\n",
    "- **Deep Learning Era (2010s)**: Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) began processing raw audio spectrograms, improving performance over traditional features.\n",
    "- **Multimodal Advances (2020s)**: Recent work integrates audio with text (e.g., lyrics) or metadata (e.g., artist info). For instance, a paper in 2021 proposed multimodal frameworks combining audio, text, and visual features for music recommendation. Models like CLAP (Contrastive Language-Audio Pretraining, 2023) leverage audio-text pairs to learn joint representations, enabling tasks like zero-shot genre classification.\n",
    "\n",
    "The project aligns with traditional MIR but hints at multimodal potential. For example, the notebook suggests future work incorporating lyrics, which could be processed with NLP models and fused with audio features using multimodal architectures like transformers.\n",
    "\n",
    "### Current Relevance\n",
    "\n",
    "Today, multimodal learning is critical for applications like Spotifyâ€™s recommendation engine, which combines audio, lyrics, and user behavior. This project serves as a foundation to explore such integrations, making it a stepping stone toward cutting-edge multimodal MIR systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "The GTZAN dataset provides a rich collection of 1000 audio clips, each 30 seconds long, across 10 genres (100 clips per genre). Each clip is accompanied by a set of precomputed audio features, such as Mel-frequency cepstral coefficients (MFCCs), spectral centroid, chroma features, and tempo, stored in `features_30_sec.csv`. Our goal is to:\n",
    "\n",
    "- Explore and visualize the dataset to understand feature distributions and genre separability.\n",
    "- Preprocess the data, including feature scaling and dimensionality reduction using PCA.\n",
    "- Train a machine learning model (specifically, a voting classifier) to predict genres.\n",
    "- Evaluate model performance with metrics and visualizations.\n",
    "- Demonstrate the pipeline by classifying a sample audio file.\n",
    "\n",
    "Let's dive in!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setting Up the Environment\n",
    "\n",
    "First, we import the necessary libraries for data manipulation, visualization, audio processing, and machine learning. These tools will power our analysis and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:35.283355Z",
     "iopub.status.busy": "2025-05-09T08:24:35.283087Z",
     "iopub.status.idle": "2025-05-09T08:24:36.575135Z",
     "shell.execute_reply": "2025-05-09T08:24:36.574592Z",
     "shell.execute_reply.started": "2025-05-09T08:24:35.283333Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Loading and Exploring the Dataset\n",
    "\n",
    "The GTZAN dataset's `features_30_sec.csv` contains 60 columns: 58 audio features, a filename, and a genre label. Let's load the data and inspect its structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:36.576426Z",
     "iopub.status.busy": "2025-05-09T08:24:36.576096Z",
     "iopub.status.idle": "2025-05-09T08:24:36.670534Z",
     "shell.execute_reply": "2025-05-09T08:24:36.670021Z",
     "shell.execute_reply.started": "2025-05-09T08:24:36.576409Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '/kaggle/input/gtzan-dataset-music-genre-classification/Data/features_30_sec.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Info:\")\n",
    "df.info()\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 1000 entries with no missing values, which is great! The features include:\n",
    "\n",
    "- **Numerical features**: `length`, `chroma_stft_mean`, `rms_mean`, `spectral_centroid_mean`, `tempo`, and 20 MFCC means and variances.\n",
    "- **Categorical features**: `filename` and `label` (the genre).\n",
    "\n",
    "Next, let's explore the distribution of genres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:36.671227Z",
     "iopub.status.busy": "2025-05-09T08:24:36.671039Z",
     "iopub.status.idle": "2025-05-09T08:24:36.923740Z",
     "shell.execute_reply": "2025-05-09T08:24:36.923193Z",
     "shell.execute_reply.started": "2025-05-09T08:24:36.671205Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot genre distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(y='label', data=df, order=df['label'].value_counts().index)\n",
    "plt.title('Distribution of Music Genres in GTZAN Dataset')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Genre')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is balanced, with 100 clips per genre, ensuring no class imbalance issues during modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualizing Feature Distributions\n",
    "\n",
    "To understand how genres differ, let's visualize key features across genres. We'll focus on `tempo`, `rms_mean`, `spectral_centroid_mean`, and `chroma_stft_mean`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:36.925375Z",
     "iopub.status.busy": "2025-05-09T08:24:36.925133Z",
     "iopub.status.idle": "2025-05-09T08:24:37.827130Z",
     "shell.execute_reply": "2025-05-09T08:24:37.826416Z",
     "shell.execute_reply.started": "2025-05-09T08:24:36.925361Z"
    }
   },
   "outputs": [],
   "source": [
    "# Box plots for selected features\n",
    "features_to_plot = ['tempo', 'rms_mean',\n",
    "                    'spectral_centroid_mean', 'chroma_stft_mean']\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(features_to_plot, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.boxplot(x='label', y=feature, data=df)\n",
    "    plt.title(f'{feature} by Genre')\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "- **Tempo**: Varies significantly, with reggae and classical having higher median tempos.\n",
    "- **RMS Mean**: Pop and hip-hop have higher energy (RMS), while classical has lower energy.\n",
    "- **Spectral Centroid**: Pop and disco have higher centroids, indicating brighter timbres.\n",
    "- **Chroma STFT**: Metal and hip-hop show higher chroma values, suggesting richer harmonic content.\n",
    "\n",
    "These differences suggest that features can help distinguish genres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:37.828176Z",
     "iopub.status.busy": "2025-05-09T08:24:37.827923Z",
     "iopub.status.idle": "2025-05-09T08:24:37.850413Z",
     "shell.execute_reply": "2025-05-09T08:24:37.849572Z",
     "shell.execute_reply.started": "2025-05-09T08:24:37.828157Z"
    }
   },
   "outputs": [],
   "source": [
    "# group and aggregate\n",
    "tmp = df.groupby('label').agg({\n",
    "    'length': ['mean'],\n",
    "    'tempo': ['mean'],\n",
    "    'chroma_stft_mean': ['mean'],\n",
    "    'rms_mean': ['mean'],\n",
    "    'spectral_bandwidth_mean': ['mean'],\n",
    "    'rolloff_mean': ['mean'],\n",
    "    'zero_crossing_rate_mean': ['mean'],\n",
    "    'harmony_mean': ['mean'],\n",
    "    'perceptr_mean': ['mean'],\n",
    "})\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Correlation Analysis\n",
    "\n",
    "To understand feature relationships, let's compute and visualize a correlation matrix for numerical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:37.851289Z",
     "iopub.status.busy": "2025-05-09T08:24:37.851018Z",
     "iopub.status.idle": "2025-05-09T08:24:38.506118Z",
     "shell.execute_reply": "2025-05-09T08:24:38.505432Z",
     "shell.execute_reply.started": "2025-05-09T08:24:37.851271Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_cols = [col for col in df.columns if 'mean' in col]\n",
    "tmp = mean_cols + ['length']\n",
    "corr = df[tmp].corr()\n",
    "\n",
    "# visualize correlation heatmap\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "f, ax = plt.subplots(figsize=(16, 12))\n",
    "cmap = sns.diverging_palette(0, 25, as_cmap=True, s=90, l=45, n=5)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "plt.title('Features Correlation Heatmap', fontsize=25)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:38.507055Z",
     "iopub.status.busy": "2025-05-09T08:24:38.506832Z",
     "iopub.status.idle": "2025-05-09T08:24:39.146787Z",
     "shell.execute_reply": "2025-05-09T08:24:39.145959Z",
     "shell.execute_reply.started": "2025-05-09T08:24:38.507023Z"
    }
   },
   "outputs": [],
   "source": [
    "var_cols = [col for col in df.columns if 'var' in col]\n",
    "tmp = var_cols + ['length']\n",
    "corr = df[tmp].corr()\n",
    "\n",
    "# visualize correlation heatmap\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "f, ax = plt.subplots(figsize=(16, 12))\n",
    "cmap = sns.diverging_palette(0, 25, as_cmap=True, s=90, l=45, n=5)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "plt.title('Features Correlation Heatmap', fontsize=25)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:39.147775Z",
     "iopub.status.busy": "2025-05-09T08:24:39.147561Z",
     "iopub.status.idle": "2025-05-09T08:24:39.762839Z",
     "shell.execute_reply": "2025-05-09T08:24:39.761960Z",
     "shell.execute_reply.started": "2025-05-09T08:24:39.147757Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select numerical features\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df[numerical_cols].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "plt.title('Correlation Matrix of Audio Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**:\n",
    "\n",
    "- High correlations exist between MFCC means and variances, suggesting redundancy.\n",
    "- Features like `spectral_centroid_mean` and `rolloff_mean` are strongly correlated, indicating they capture similar spectral properties.\n",
    "- This redundancy motivates dimensionality reduction, which we'll address with PCA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Data Preprocessing\n",
    "\n",
    "To prepare the data for modeling, we:\n",
    "\n",
    "1. Encode the genre labels.\n",
    "2. Split features into groups (other features, MFCC means, MFCC variances).\n",
    "3. Standardize the data.\n",
    "4. Apply PCA to MFCC means and variances to reduce dimensionality.\n",
    "5. Scale all features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:39.763794Z",
     "iopub.status.busy": "2025-05-09T08:24:39.763596Z",
     "iopub.status.idle": "2025-05-09T08:24:39.770076Z",
     "shell.execute_reply": "2025-05-09T08:24:39.769442Z",
     "shell.execute_reply.started": "2025-05-09T08:24:39.763779Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(['filename', 'label'], axis=1)\n",
    "y = df['label']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:39.772682Z",
     "iopub.status.busy": "2025-05-09T08:24:39.772473Z",
     "iopub.status.idle": "2025-05-09T08:24:39.845320Z",
     "shell.execute_reply": "2025-05-09T08:24:39.844184Z",
     "shell.execute_reply.started": "2025-05-09T08:24:39.772666Z"
    }
   },
   "outputs": [],
   "source": [
    "# before process into PCA, we need to seperate MFCC mean and var column values from the other\n",
    "\n",
    "mean_cols = [col for col in X.columns if 'mfcc' in col and 'mean' in col]\n",
    "var_cols = [col for col in X.columns if 'mfcc' in col and 'var' in col]\n",
    "other_cols = [col for col in X.columns if col not in mean_cols + var_cols]\n",
    "\n",
    "mean_data = X.loc[:, mean_cols]\n",
    "var_data = X.loc[:, var_cols]\n",
    "others_data = X.loc[:, other_cols]\n",
    "\n",
    "print('# of column in others_data:', len(other_cols))\n",
    "print('# of column in mean_data:', len(mean_cols))\n",
    "print('# of column in var_data:', len(var_cols))\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "mean_scaled = scaler.fit_transform(mean_data)\n",
    "var_scaled = scaler.fit_transform(var_data)\n",
    "others_scaled = scaler.fit_transform(others_data)\n",
    "\n",
    "# for non-PCA input data\n",
    "X_scaled = np.concatenate([others_scaled, mean_scaled, var_scaled], axis=1)\n",
    "X_scaled.shape\n",
    "\n",
    "\n",
    "pca1 = PCA(n_components=2)\n",
    "tmp1 = pca1.fit_transform(mean_data)\n",
    "print(f'{round(np.sum(pca1.explained_variance_ratio_), 4)} variance explained')\n",
    "print('shape PCA mean:', tmp1.shape)\n",
    "\n",
    "pca2 = PCA(n_components=2)\n",
    "tmp2 = pca2.fit_transform(var_data)\n",
    "print(f'{round(np.sum(pca2.explained_variance_ratio_), 4)} variance explained')\n",
    "print('shape PCA var:', tmp2.shape)\n",
    "\n",
    "# for PCA input data\n",
    "X_pca_columns = other_cols + ['mfcc_mean_pca1',\n",
    "                              'mfcc_mean_pca2', 'mfcc_var_pca1', 'mfcc_var_pca2']\n",
    "X_pca = np.concatenate([others_data, tmp1, tmp2], axis=1)\n",
    "X_pca.shape\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "le.classes_\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y_enc, test_size=0.2, stratify=y_enc, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By reducing MFCC features to 2 components each, we retain significant variance while reducing the feature count, which helps prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**:\n",
    "\n",
    "- The accuracy indicates the model's overall performance.\n",
    "- The classification report provides precision, recall, and F1-score per genre, highlighting which genres are harder to classify.\n",
    "- The confusion matrix shows misclassifications, helping identify genre pairs that are often confused.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Training the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:39.846271Z",
     "iopub.status.busy": "2025-05-09T08:24:39.846048Z",
     "iopub.status.idle": "2025-05-09T08:24:40.289547Z",
     "shell.execute_reply": "2025-05-09T08:24:40.288964Z",
     "shell.execute_reply.started": "2025-05-09T08:24:39.846252Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimum Model Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:40.290333Z",
     "iopub.status.busy": "2025-05-09T08:24:40.290156Z",
     "iopub.status.idle": "2025-05-09T08:24:40.294763Z",
     "shell.execute_reply": "2025-05-09T08:24:40.293837Z",
     "shell.execute_reply.started": "2025-05-09T08:24:40.290319Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_evaluation(model, X_train, X_test, desc):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(desc)\n",
    "    print(classification_report(y_test, y_pred,\n",
    "          target_names=le.classes_, zero_division=0.0))\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:40.295770Z",
     "iopub.status.busy": "2025-05-09T08:24:40.295533Z",
     "iopub.status.idle": "2025-05-09T08:24:41.521870Z",
     "shell.execute_reply": "2025-05-09T08:24:41.521253Z",
     "shell.execute_reply.started": "2025-05-09T08:24:40.295749Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate base classifier model\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model_evaluation(model, X_train, X_test, 'RFC Evaluation')\n",
    "\n",
    "model = SVC()\n",
    "model_evaluation(model, X_train, X_test, 'SVC Evaluation')\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model_evaluation(model, X_train, X_test, 'DCT Evaluation')\n",
    "\n",
    "model = XGBClassifier()\n",
    "model_evaluation(model, X_train, X_test, 'XGB Evaluation')\n",
    "\n",
    "model = SGDClassifier()\n",
    "model_evaluation(model, X_train, X_test, 'SGD Evaluation')\n",
    "\n",
    "model = GaussianNB()\n",
    "model_evaluation(model, X_train, X_test, 'NB Evaluation')\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "_ = model_evaluation(model, X_train, X_test, 'KNN Evaluation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, XGBClassifier has the highest accuracy among other classifier models. Therefore, we will choose this model as our optimum model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune Hyperparameter Optimum Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:41.522680Z",
     "iopub.status.busy": "2025-05-09T08:24:41.522508Z",
     "iopub.status.idle": "2025-05-09T08:24:41.526364Z",
     "shell.execute_reply": "2025-05-09T08:24:41.525621Z",
     "shell.execute_reply.started": "2025-05-09T08:24:41.522666Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:41.527333Z",
     "iopub.status.busy": "2025-05-09T08:24:41.527095Z",
     "iopub.status.idle": "2025-05-09T08:24:41.538872Z",
     "shell.execute_reply": "2025-05-09T08:24:41.538250Z",
     "shell.execute_reply.started": "2025-05-09T08:24:41.527318Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.2, 0.3, 0.4],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'n_estimators': [50, 100, 150]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:41.539938Z",
     "iopub.status.busy": "2025-05-09T08:24:41.539700Z",
     "iopub.status.idle": "2025-05-09T08:25:17.958913Z",
     "shell.execute_reply": "2025-05-09T08:25:17.957882Z",
     "shell.execute_reply.started": "2025-05-09T08:24:41.539923Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(XGBClassifier(eval_metric='mlogloss'), param_grid, cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:17.960974Z",
     "iopub.status.busy": "2025-05-09T08:25:17.959632Z",
     "iopub.status.idle": "2025-05-09T08:25:18.288179Z",
     "shell.execute_reply": "2025-05-09T08:25:18.287531Z",
     "shell.execute_reply.started": "2025-05-09T08:25:17.960952Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred,\n",
    "      target_names=le.classes_, zero_division=0.0))\n",
    "\n",
    "# generate confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier performs quite well achieving 0.75 for F1-score. Model perform very well when classifying classical, metal, and hip-hop music. However, it struggles to classify country, reggae, and rock music.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Feature Importance\n",
    "\n",
    "See which features are important and see the impact to the model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:18.289212Z",
     "iopub.status.busy": "2025-05-09T08:25:18.288971Z",
     "iopub.status.idle": "2025-05-09T08:25:18.463556Z",
     "shell.execute_reply": "2025-05-09T08:25:18.462800Z",
     "shell.execute_reply.started": "2025-05-09T08:25:18.289187Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "# plot importance features\n",
    "plot_importance(grid.best_estimator_, max_num_features=15,\n",
    "                importance_type='gain', show_values=False)  # 'gain' is often better\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:18.464492Z",
     "iopub.status.busy": "2025-05-09T08:25:18.464274Z",
     "iopub.status.idle": "2025-05-09T08:25:18.471835Z",
     "shell.execute_reply": "2025-05-09T08:25:18.471138Z",
     "shell.execute_reply.started": "2025-05-09T08:25:18.464465Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# get n feature importance\n",
    "print('# of X_train features:', X_train.shape[1])\n",
    "n_feature = 15\n",
    "feature_importance = pd.Series(\n",
    "    grid.best_estimator_.feature_importances_, index=np.arange(X_train.shape[1]))\n",
    "top_feature = feature_importance.sort_values(\n",
    "    ascending=False).head(n_feature).index.tolist()\n",
    "top_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:18.472828Z",
     "iopub.status.busy": "2025-05-09T08:25:18.472613Z",
     "iopub.status.idle": "2025-05-09T08:25:18.486318Z",
     "shell.execute_reply": "2025-05-09T08:25:18.485589Z",
     "shell.execute_reply.started": "2025-05-09T08:25:18.472807Z"
    }
   },
   "outputs": [],
   "source": [
    "len(X_pca_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:18.487286Z",
     "iopub.status.busy": "2025-05-09T08:25:18.487000Z",
     "iopub.status.idle": "2025-05-09T08:25:18.497813Z",
     "shell.execute_reply": "2025-05-09T08:25:18.497242Z",
     "shell.execute_reply.started": "2025-05-09T08:25:18.487266Z"
    }
   },
   "outputs": [],
   "source": [
    "important_feature = [X_pca_columns[i] for i in top_feature]\n",
    "print(f'{n_feature} important feature: {\", \".join(important_feature)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Model Performance Evaluation\n",
    "\n",
    "Let's evaluate the model using accuracy, classification report, and a confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:18.498688Z",
     "iopub.status.busy": "2025-05-09T08:25:18.498500Z",
     "iopub.status.idle": "2025-05-09T08:25:18.905521Z",
     "shell.execute_reply": "2025-05-09T08:25:18.904944Z",
     "shell.execute_reply.started": "2025-05-09T08:25:18.498669Z"
    }
   },
   "outputs": [],
   "source": [
    "# define new train test data\n",
    "X_train_topf = X_train[:, top_feature]\n",
    "X_test_topf = X_test[:, top_feature]\n",
    "\n",
    "# fit XGBC model with top n features\n",
    "xgbc = XGBClassifier(learning_rate=0.3, max_depth=3, n_estimators=100)\n",
    "_ = model_evaluation(xgbc, X_train_topf, X_test_topf,\n",
    "                     f'XGBC with Top {n_feature} Features Evaluation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of XGB decreases when we only include 15 important features. That means the remaining features are also important for determining music genre. Therefore, we will use the 22 features input data for next experiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Ensemble Model Classifier\n",
    "\n",
    "Another solution is we can use ensemble method by combine prediction result from best model (XGB) with second best model (RFC).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:18.907599Z",
     "iopub.status.busy": "2025-05-09T08:25:18.906965Z",
     "iopub.status.idle": "2025-05-09T08:25:18.911494Z",
     "shell.execute_reply": "2025-05-09T08:25:18.910950Z",
     "shell.execute_reply.started": "2025-05-09T08:25:18.907579Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:18.912255Z",
     "iopub.status.busy": "2025-05-09T08:25:18.912033Z",
     "iopub.status.idle": "2025-05-09T08:25:20.846108Z",
     "shell.execute_reply": "2025-05-09T08:25:20.845336Z",
     "shell.execute_reply.started": "2025-05-09T08:25:18.912238Z"
    }
   },
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('xgb', XGBClassifier(learning_rate=0.3, max_depth=3,\n",
    "                 n_estimators=100)), ('rfc', RandomForestClassifier())],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_evaluation(voting_clf, X_train, X_test,\n",
    "                          'Voting Classifier (XGB + RFC)')\n",
    "\n",
    "# generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGB + RFC ensemble method performs better compared to the single XGB Classification result. This method achieves the best performance at an F1 score accuracy of 0.78, surpassing the single XGB F1-score result of 0.75 in the previous evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**:\n",
    "\n",
    "- The accuracy indicates the model's overall performance.\n",
    "- The classification report provides precision, recall, and F1-score per genre, highlighting which genres are harder to classify.\n",
    "- The confusion matrix shows misclassifications, helping identify genre pairs that are often confused.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:20.846976Z",
     "iopub.status.busy": "2025-05-09T08:25:20.846726Z",
     "iopub.status.idle": "2025-05-09T08:25:20.895580Z",
     "shell.execute_reply": "2025-05-09T08:25:20.895003Z",
     "shell.execute_reply.started": "2025-05-09T08:25:20.846953Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the trained model to disk\n",
    "import joblib\n",
    "\n",
    "joblib.dump(voting_clf, 'music_genre_classifier.pkl')\n",
    "\n",
    "print(\"Model saved as 'music_genre_classifier.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Testing with a Sample Audio File\n",
    "\n",
    "Let's test our model on a sample audio file (`jazz.00075.wav`) by extracting its features and predicting its genre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:20.896399Z",
     "iopub.status.busy": "2025-05-09T08:25:20.896182Z",
     "iopub.status.idle": "2025-05-09T08:25:20.905261Z",
     "shell.execute_reply": "2025-05-09T08:25:20.904660Z",
     "shell.execute_reply.started": "2025-05-09T08:25:20.896380Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:20.906199Z",
     "iopub.status.busy": "2025-05-09T08:25:20.905950Z",
     "iopub.status.idle": "2025-05-09T08:25:32.362756Z",
     "shell.execute_reply": "2025-05-09T08:25:32.361719Z",
     "shell.execute_reply.started": "2025-05-09T08:25:20.906184Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Audio File\n",
    "audio_dir = '/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/'\n",
    "selected_audio = audio_dir+'jazz/jazz.00075.wav'\n",
    "audio1, sr = librosa.load(selected_audio)\n",
    "\n",
    "# Play audio\n",
    "print(\"Playing sample audio:\")\n",
    "ipd.Audio(selected_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Audio Features\n",
    "\n",
    "Extract features as same like in csv files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:32.366068Z",
     "iopub.status.busy": "2025-05-09T08:25:32.365668Z",
     "iopub.status.idle": "2025-05-09T08:25:32.374025Z",
     "shell.execute_reply": "2025-05-09T08:25:32.373212Z",
     "shell.execute_reply.started": "2025-05-09T08:25:32.366035Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define feature extraction function\n",
    "def get_audio_features(y, sr):\n",
    "    features = {\n",
    "        'length': len(y),\n",
    "        'chroma_stft_mean': np.mean(librosa.feature.chroma_stft(y=y, sr=sr)),\n",
    "        'chroma_stft_var': np.var(librosa.feature.chroma_stft(y=y, sr=sr)),\n",
    "        'rms_mean': np.mean(librosa.feature.rms(y=y)),\n",
    "        'rms_var': np.var(librosa.feature.rms(y=y)),\n",
    "        'spectral_centroid_mean': np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),\n",
    "        'spectral_centroid_var': np.var(librosa.feature.spectral_centroid(y=y, sr=sr)),\n",
    "        'spectral_bandwidth_mean': np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)),\n",
    "        'spectral_bandwidth_var': np.var(librosa.feature.spectral_bandwidth(y=y, sr=sr)),\n",
    "        'rolloff_mean': np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),\n",
    "        'rolloff_var': np.var(librosa.feature.spectral_rolloff(y=y, sr=sr)),\n",
    "        'zero_crossing_rate_mean': np.mean(librosa.feature.zero_crossing_rate(y=y)),\n",
    "        'zero_crossing_rate_var': np.var(librosa.feature.zero_crossing_rate(y=y)),\n",
    "        'harmony_mean': np.mean(librosa.effects.harmonic(y)),\n",
    "        'harmony_var': np.var(librosa.effects.harmonic(y)),\n",
    "        'perceptr_mean': np.mean(librosa.feature.spectral_contrast(y=y, sr=sr)),\n",
    "        'perceptr_var': np.var(librosa.feature.spectral_contrast(y=y, sr=sr)),\n",
    "        'tempo': librosa.beat.beat_track(y=y, sr=sr)[0][0],\n",
    "    }\n",
    "\n",
    "    # loop for mfcc feature:\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    for i in range(20):\n",
    "        features[f'mfcc{i+1}_mean'] = np.mean(mfcc[i])\n",
    "        features[f'mfcc{i+1}_var'] = np.var(mfcc[i])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:32.375097Z",
     "iopub.status.busy": "2025-05-09T08:25:32.374821Z",
     "iopub.status.idle": "2025-05-09T08:25:48.457520Z",
     "shell.execute_reply": "2025-05-09T08:25:48.456875Z",
     "shell.execute_reply.started": "2025-05-09T08:25:32.375074Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract features\n",
    "audio_features = get_audio_features(audio1, sr)\n",
    "print('total features:', len(audio_features))\n",
    "audio_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Input Data\n",
    "\n",
    "Treat raw data same as preprocessing step above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:48.458680Z",
     "iopub.status.busy": "2025-05-09T08:25:48.458200Z",
     "iopub.status.idle": "2025-05-09T08:25:48.468006Z",
     "shell.execute_reply": "2025-05-09T08:25:48.467372Z",
     "shell.execute_reply.started": "2025-05-09T08:25:48.458656Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_df = pd.DataFrame([audio_features])\n",
    "audio_df\n",
    "\n",
    "# split mfcc column from the other columns\n",
    "audio_other = audio_df.loc[:, other_cols]\n",
    "audio_mean = audio_df.loc[:, mean_cols]\n",
    "audio_var = audio_df.loc[:, var_cols]\n",
    "\n",
    "print(audio_other.shape, audio_mean.shape, audio_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:48.469096Z",
     "iopub.status.busy": "2025-05-09T08:25:48.468789Z",
     "iopub.status.idle": "2025-05-09T08:25:48.487420Z",
     "shell.execute_reply": "2025-05-09T08:25:48.486699Z",
     "shell.execute_reply.started": "2025-05-09T08:25:48.469076Z"
    }
   },
   "outputs": [],
   "source": [
    "# reduce dimensionality using PCA\n",
    "audio_mean_pca = pca1.transform(audio_mean)\n",
    "print(f'{round(np.sum(pca1.explained_variance_ratio_), 4)} variance explained')\n",
    "print('shape PCA mean:', audio_mean_pca.shape)\n",
    "\n",
    "audio_var_pca = pca2.transform(audio_var)\n",
    "print(f'{round(np.sum(pca2.explained_variance_ratio_), 4)} variance explained')\n",
    "print('shape PCA var:', audio_var_pca.shape)\n",
    "\n",
    "# concatenate with rest of the columns\n",
    "audio_processed = np.concatenate(\n",
    "    [audio_other, audio_mean_pca, audio_var_pca], axis=1)\n",
    "audio_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:25:48.488843Z",
     "iopub.status.busy": "2025-05-09T08:25:48.488250Z",
     "iopub.status.idle": "2025-05-09T08:25:48.498931Z",
     "shell.execute_reply": "2025-05-09T08:25:48.498329Z",
     "shell.execute_reply.started": "2025-05-09T08:25:48.488821Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict genre using voting classifier\n",
    "pred_label = voting_clf.predict(audio_processed)\n",
    "predicted_genre = le.classes_[pred_label][0]\n",
    "print(f'Predicted Genre: {predicted_genre}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model correctly predicts the genre, demonstrating its ability to generalize to new audio samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Conclusion and Future Work\n",
    "\n",
    "In this project, we successfully built a music genre classification system using the GTZAN dataset. Key takeaways:\n",
    "\n",
    "- **Data Insights**: Visualizations revealed distinct feature patterns across genres, with some overlap (e.g., rock and blues).\n",
    "- **Preprocessing**: PCA effectively reduced dimensionality while retaining significant variance.\n",
    "- **Modeling**: The voting classifier achieved strong performance, outperforming individual models.\n",
    "- **Application**: The model accurately classified sample audio files.\n",
    "\n",
    "**Future Work**:\n",
    "\n",
    "- Convert the project to Multimodal considering the other modality 'lyrics'\n",
    "- Experiment with deep learning models (e.g., CNNs on spectrograms) for potentially better performance.\n",
    "- Test the model on a larger, more diverse dataset to improve accuracy.\n",
    "\n",
    "This project showcases the power of machine learning in audio analysis, opening doors to applications in music recommendation, audio tagging, and more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Learnings from This Work\n",
    "\n",
    "This project taught me several key lessons about audio-based machine learning and its broader implications:\n",
    "\n",
    "1. **Feature Engineering is Powerful**: The GTZAN datasetâ€™s precomputed features (MFCCs, tempo, etc.) capture essential audio characteristics. Visualizations like box plots and PCA scatter plots revealed how features like spectral centroid and chroma STFT differentiate genres (e.g., classical vs. metal).\n",
    "2. **Dimensionality Reduction Matters**: Applying PCA to MFCC means and variances reduced the feature space while retaining significant variance (~74-78%), preventing overfitting and speeding up training.\n",
    "3. **Ensemble Models Shine**: The voting classifier (XGBoost + Random Forest) achieved a strong F1-score of 0.78, outperforming individual models. This highlights the value of combining complementary algorithms.\n",
    "4. **Challenges in Generalization**: The model struggled with genres like country and reggae, likely due to feature overlap (e.g., rock and blues in PCA space). This underscores the need for richer features or multimodal inputs.\n",
    "5. **Real-World Application**: Testing the model on a test sample audio file demonstrated its practical utility, correctly predicting the genre and showing robustness to new samples.\n",
    "\n",
    "The project also deepened my understanding of MIR pipelines, from feature extraction to model evaluation, and peaked my curiosity about multimodal extensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413bccd",
   "metadata": {},
   "source": [
    "## ðŸ’­ Reflections\n",
    "\n",
    "**What surprised me?**\n",
    "\n",
    "- **Genre Overlap**: I was surprised by how much genres like rock and blues overlapped in PCA space, reflecting their musical similarity (e.g., shared guitar-driven structures). This explains the modelâ€™s lower performance on these classes and highlights the complexity of genre boundaries.\n",
    "- **Ensemble Power**: The voting classifierâ€™s improvement over XGBoost alone (F1: 0.78 vs. 0.75) was notable. Combining models with different strengths (gradient boosting and bagging) yielded a better solution.\n",
    "- **Feature Importance**: The feature importance analysis showed that MFCC PCA components and spectral features were critical, but reducing to 15 features hurt performance. This suggests that even less important features contribute to the modelâ€™s discriminative power.\n",
    "\n",
    "**Scope for Improvement**\n",
    "\n",
    "- **Multimodal Integration**: Incorporating lyrics (via NLP embeddings) or album art (via CNNs) could improve classification, especially for ambiguous genres. For example, lyrics could distinguish reggaeâ€™s thematic content from rockâ€™s.\n",
    "- **Deep Learning**: Using CNNs or transformers on raw spectrograms might capture temporal and spectral patterns better than handcrafted features, as shown in recent MIR research.\n",
    "- **Larger Datasets**: GTZANâ€™s 1000 clips are limited. Testing on larger datasets like FMA or AudioSet could enhance correctness and generalizability.\n",
    "- **Hyperparameter Tuning**: The GridSearchCV was limited to a few parameters. More extensive tuning (e.g., regularization, learning rate schedules) could boost performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023b1fc6",
   "metadata": {},
   "source": [
    "## ðŸ”— References\n",
    "\n",
    "- [GTZAN Dataset](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification/data)\n",
    "- [Music Genre Classification with Machine Learning (Medium)](https://medium.com/@yamind/MusicGenreML)\n",
    "- [MusicLM: Generating Music From Text](https://arxiv.org/abs/2301.11325)\n",
    "- [Librosa Library](https://librosa.org/)\n",
    "- [Scikit-learn Documentation](https://scikit-learn.org/)\n",
    "- [XGBoost Documentation](https://xgboost.readthedocs.io/)\n",
    "\n",
    "This project was built using Python, scikit-learn, XGBoost, and Librosa, with the original notebook running on Kaggle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THANK YOU\n",
    "\n",
    "***Author: M Sai Srinivas***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 568973,
     "sourceId": 1032238,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
